{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ef9e26",
   "metadata": {},
   "source": [
    "### Models\n",
    "* AutoModel class\n",
    "    * handy when you want to instatiate any model from a checkpoint\n",
    "    * wrappers over the wide variety of models available\n",
    "    * Automatically guess appropriate model architecture for checkpoint, then instantiates model w/ architecture\n",
    "* If you know what model you want to use, you can use the class that defines its architecture directly\n",
    "    * EG BERT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d843dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.52.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# Building the config\n",
    "config = BertConfig() #By leaving this empty, it will use the default configuration\n",
    "# You can also customize the configuration by passing parameters\n",
    "\n",
    "# Building the model from the config\n",
    "model = BertModel(config)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297be6eb",
   "metadata": {},
   "source": [
    "* Hidden size attribute defines size of hidden_states vector\n",
    "* num_hidden_layers defines the number of layers the transformer model has\n",
    "### Different Loading Methods\n",
    "* Creating model from default config initializes it with random values\n",
    "```python\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "config = BertConfig()\n",
    "model = BertModel(config)\n",
    "\n",
    "# Model is randomly initialized!\n",
    "```\n",
    "* Can be used in this state but will output gibberish as it needs to be trained.\n",
    "    * Thus why we load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb13ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pretrained Model\n",
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940898c1",
   "metadata": {},
   "source": [
    "* We can replace BertModel with equivalent AutoModel class\n",
    "    * Using automodel allows you to use the code across checkpoints\n",
    "* When we use models, they're downloaded and cached in the cache folder\n",
    "    * initialized with all weights of the checkpoint, can be used directly for tasks it was trained on or fine-tuned to new tasks\n",
    "#### Saving Methods\n",
    "* To save a model outside the cache, we use save_pretrained() method, same as from pretrained\n",
    "\n",
    "```python\n",
    "model.save_pretrained(\"directory_on_computer\")\n",
    "```\n",
    "* This saves two files, config.json & pytorch_model.bin\n",
    "    * Config.json = attributes necessary for model architecture, metadata (like checkpoint originated & what HFT version used when last saved)\n",
    "    * pytorch_model.bin = **State Directory** containing weights.\n",
    "### Using a Transformer model for inference\n",
    "* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
